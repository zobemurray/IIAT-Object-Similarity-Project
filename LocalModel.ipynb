{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba9687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "#using torch rather than the keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fc1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_path):\n",
    "    '''\n",
    "        goes through all the files in folder, converts them to \n",
    "        greyscale and processes them to be used for the models\n",
    "    '''\n",
    "    images = []\n",
    "    image_names = []\n",
    "    for filename in os.listdir(image_path):\n",
    "        if filename.lower().endswith(('.jpg')):\n",
    "            img_path = os.path.join(image_path, filename)\n",
    "            img = Image.open(img_path).convert(\"L\")#converting image to greyscale\n",
    "            img = img.convert(\"L\")\n",
    "            img = np.array(img)#converting from pillow obj to NumPy array\n",
    "            img_3ch = np.stack([img, img, img], axis=-1)#duplicating channels\n",
    "            img_3ch = Image.fromarray(img_3ch.astype(np.uint8)) #converting back to pillow obj\n",
    "            images.append(img_3ch)\n",
    "            image_names.append(filename)\n",
    "    return images, image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498760d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    '''\n",
    "        processes image by resizing it to 224x224, converting it \n",
    "        to a PyTorch tensor (data structure used in deep learning), and \n",
    "        normalizes the image using ImageNet mean and std values\n",
    "\n",
    "    '''\n",
    "    return transforms.Compose([transforms.Resize((224, 224)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                    std=[0.229, 0.244, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7934d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        raise ValueError(\"Not an available model.\")\n",
    "    model.eval()#turns off batch normalization updates\n",
    "    #returning feature vectors\n",
    "    return torch.nn.Sequential(*(list(model.children())[:-1]))#returns models without final class. layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2db781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, images):\n",
    "    transform = get_transform()\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img_t = transform(img).unsqueeze(0)#adding a batch dimension\n",
    "        with torch.no_grad():#disables gradient computation\n",
    "            feat = model(img_t)\n",
    "            feat = feat.view(feat.size(0), -1)#making output a 1D vector\n",
    "            features.append(feat.numpy()[0]) #changing it into a numpy array and appending to features\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ab7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_similarity(features, image_names):\n",
    "    sim_matrix = cosine_similarity(features)\n",
    "    df = pd.DataFrame(sim_matrix, index=image_names, columns=image_names)\n",
    "    return df, sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bf7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, output_path):\n",
    "    df.to_csv(output_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c27b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(df, output_path):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df, annot=False, cmap=\"coolwarm\", xticklabels=True, yticklabels=True)\n",
    "    plt.title(\"Pairwise Image Similarity Heatmap\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1255f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_comparison(model_name, image_path):\n",
    "    images, image_names = load_images(image_path)\n",
    "    model = load_model(model_name)\n",
    "    features = extract_features(model, images)\n",
    "    df, sim_matrix = compute_pairwise_similarity(features, image_names)\n",
    "    save_to_csv(df, 'pairwise_results.csv')\n",
    "    generate_heatmap(df, 'pairwise_heatmap.png')\n",
    "    labels = extract_labels(image_names)\n",
    "    #labels = image_names\n",
    "    accuracy = category_similarity_accuracy(sim_matrix, labels)\n",
    "    print(f\"Category Similarity Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17b0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(image_names):\n",
    "    return np.array([name.split(\"_\")[1][:4] for name in image_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08676435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_similarity_accuracy(sim_matrix, labels):\n",
    "    same_class_sims = []\n",
    "    diff_class_sims = []\n",
    "    n = len(labels)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if labels[i] == labels[j]:\n",
    "                same_class_sims.append(sim_matrix[i, j])\n",
    "            else:\n",
    "                diff_class_sims.append(sim_matrix[i, j])\n",
    "    threshold = np.median(diff_class_sims)\n",
    "    correct = sum(sim > threshold for sim in same_class_sims)\n",
    "    accuracy = correct / len(same_class_sims)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a763566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in images\n",
      "Completed\n",
      "preparing model\n",
      "Category Similarity Accuracy: 0.972\n",
      "outputting comparisons\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading in images\")\n",
    "image_path = r\"C:\\Users\\zobes\\OneDrive\\SummerResearch\\grey_images\"\n",
    "print(\"Completed\")\n",
    "#image_path = input(\"Enter the folder path with grey images: \")\n",
    "model_name = input(\"Enter the method you would like to use for image comparison (vgg16 or resnet50): \")\n",
    "print(\"preparing model\")\n",
    "image_comparison(model_name, image_path)\n",
    "print(\"outputting comparisons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
